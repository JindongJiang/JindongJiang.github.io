<!DOCTYPE html>
<html lang="en">

<head>
    <title>Jindong Jiang</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono" rel="stylesheet">
    <style>
        /* Remove the navbar's default margin-bottom and rounded borders */
        .navbar {
            margin-bottom: 0;
            border-radius: 0;
        }

        /*div.content { width: 1000px;     margin-left: auto;*/
        /*margin-right: auto; }*/

        body {
            margin: 1em auto;
            max-width: 60%;
            /*font-family: 'Lato', sans-serif;*/
            /* font-family: Gill Sans, Gill Sans MT, Calibri; */
            font-family: "Ubuntu", sans-serif;
            /* font-family: "Ubuntu Mono", sans-serif; */
            font-size: 20px;
            color: #333;
            font-weight: 300;
        }

        .dest {
            font-family: "Comic Sans MS";
            /* font-size: 16px;
            margin-left: .9em; */
            /* margin-left: .9em;
  margin-top: .1em; */
            /* color: rgb(51, 0, 51); */
        }

        .special {
            font-family: "Comic Sans MS";
            /* font-size: 16px; */
            /* margin-left: 1.9em; */
            /* margin-left: .9em;
  margin-top: .1em; */
            /* color: rgb(255, 156, 64); */
            color: rgb(241, 110, 45)
        }

        /* Add a gray background color and some padding to the footer */
        footer {
            background-color: #f2f2f2;
            padding: 25px;
        }

        .header {
            margin-bottom: 20px;
            /* padding-bottom: 20px; */
        }

        .header .profile_image {
            display: block;
            margin-left: auto;
            margin-right: auto;
            max-width: 25%;
            height: auto;
            border-radius: 50%;
            /* float: left; */
        }

        a,
        a:hover {
            /* color: #a00; */
            color: rgb(187, 116, 56);
            text-decoration: none;
        }

        html,
        button,
        input,
        select,
        textarea {
            color: #222;
        }

        ::-moz-selection {
            background: #b3d4fc;
            text-shadow: none;
        }

        ::selection {
            background: #b3d4fc;
            text-shadow: none;
        }

        .publications {
            /* margin-left: 0em; */
        }

        .collaborators {
            /* margin-left: 0em; */
        }


        /* Jd */
        .pdf_project {
            font-family: "Ubuntu Mono";
            /* font-size: 16px;
            margin-left: .1em;
            margin-top: .1em; */
        }

        .vspace_small {
            margin-top: 20px;
            margin-bottom: 20px;
        }

        @media (max-width: 992px) {
            body {
                max-width: 80%;
                font-size: 18px;
            }

            .header .profile_image {
                max-width: 30%;
            }
        }

        /* set the body's max-width to 90% on devices with a width of 768px or less, */
        /* making it more responsive on mobile devices. */
        @media (max-width: 768px) {
            body {
                max-width: 90%;
                font-size: 16px;
            }

            .header .profile_image {
                max-width: 40%;
            }
        }

        @media (max-width: 480px) {
            body {
                max-width: 95%;
                font-size: 14px;
            }

            .header .profile_image {
                max-width: 50%;
            }
        }
    </style>
</head>

<body>


    <div class="content container">
        <!-- <div class="container wrapper"> -->
        <div class="header">
            <img src=https://JindongJiang.github.io/profile.jpg class="profile_image">
            <h1>Jindong Jiang</h1>
            <p>PhD Student &middot; Rutgers University</p>
            <p>Email: jindong.jiang at rutgers.edu &middot; <a
                    href="https://scholar.google.com/citations?user=6oo8xOQAAAAJ&hl=en">Google Scholar</a> &middot;
                <a href="https://github.com/JindongJiang">GitHub</a>
            </p>
            <!-- <div class="contact-info">
                <p class="email">Email: firstname.lastname at rutgers.edu</p>
                <div class="links">
                    <a href="https://scholar.google.com/citations?user=6oo8xOQAAAAJ&hl=en">Google Scholar</a> &middot;
                    <a href="https://github.com/JindongJiang">GitHub</a>
                </div>
            </div> -->
            <!-- <p>&nbsp;</p> -->
            <!-- <p>&thinsp;</p> -->
            <hr />
            <h3>About</h3>
            <p>I am a PhD student at Rutgers University under the supervision of <a href="https://www.sungjinahn.com">Prof. Sungjin
                    Ahn</a>.
                <!-- My research interests lie in the unsupervised learning of controllable and interpretable generative
                models,
                which I believe are critical for the practical application and widespread adoption of AI systems. -->
                My research interests lie at the intersection of structured representation learning and generative world models,
                with a strong focus on developing unsupervised/self-supervised techniques.
            </p>
            <p>
                The long-term objective of my research is to develop artificial intelligence agents capable of human-like reasoning. This involves designing systems that can uncover latent structure of the physical world, predict future scenarios based on current states, infer the causality or correlation between events, and engage in logical planning to accomplish goals. 
            </p>
            <p>
                At current stage, I am focusing on developing scalable model designs that could improve AI's ability to understand and interpret complex environments.
            </p>
            <span>
                <b>Interests.&nbsp;</b> Image/Video Perception, Diffusion Models, State Space Models
            </span>
            <!-- <p>&thinsp;</p> -->
            <hr />
            <h3>News</h3>
            <ul>
                <li><em>Sep 2024: </em>Our <a
                    href="https://slotssms.github.io/">Slot State Space Models</a> is accepted to <span class="dest">NeurIPS 2024</span>!</li>
                <li><em>June 2024: </em>Preprint of our new work, <a
                    href="https://slotssms.github.io/">Slot State Space Models</a>,
                for modular sequence modeling, is out on arXiv!</li>
                <li><em>June 2024: </em>I joined <a href="https://research.nvidia.com/labs/lpr/">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/NVIDIA_logo.svg/2560px-NVIDIA_logo.svg.png"
                            alt="Nvidia" style="width: auto; height: 20px; vertical-align: middle;"> Learning and Perception Research Group</a> as a Research
                    Intern in the Summer of 2024!
                </li>
                <li><em>Feb 2024: </em>Our <a href="https://arxiv.org/abs/2406.01062">Layout-Agnostic Scene Text Image Synthesis with Diffusion Models</a> is accepted to <span class="dest">CVPR 2024</span>!</li>
                <li><em>Sep 2023: </em>Our <a href="https://latentslotdiffusion.github.io/">Object-Centric Slot Diffusion</a> is accepted to <span class="dest">NeurIPS 2023</span> as
                    a ðŸŒŸSpotlightðŸŒŸ paper!</li>
                <li><em>Apr 2023: </em>Our <a href="https://generative-vision.github.io/workshop-CVPR-23/data/33.pdf">Object-Centric Slot Diffusion for Unsupervised Compositional Generation</a>,
                    is accepted to <span class="dest">CVPR 2023</span> <a href="https://generative-vision.github.io/workshop-CVPR-23/">GCV Workshop</a>!</li>
                <!-- <li><em>Mar 2023: </em>Preprint of our new work, <a
                        href="https://arxiv.org/abs/2303.10834">Object-Centric Slot Diffusion</a>,
                    for unsupervised object-centric learning using Diffusion Models, is out on arXiv!</li> -->
                <li><em>Feb 2023: </em>I will be joining <a href="https://research.adobe.com/">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Adobe_Corporate_logo.svg/2880px-Adobe_Corporate_logo.svg.png"
                            alt="Adobe" style="width: auto; height: 20px; vertical-align: middle;"></a> as a Research
                    Scientist Intern in the Summer of 2023!
                </li>
            </ul>
            <!-- <h3>Old News</h3> -->
            <!-- <p>&thinsp;</p> -->
            <hr />
            <h3>Publications</h3>
            <div class="vspace_small"></div>
            <ul>
                <li>
                    <p class="publications">Slot State Space Models</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                <span style="text-decoration: underline;">Jindong Jiang</span>, Fei Deng, Gautam Singh, Minseung Lee, Sungjin Ahn
                            </span>
                        </li>
                        <li>
                            <span class="dest"> NeurIPS 2024 </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/2406.12272">paper</a>]
                                [<a href="https://slotssms.github.io/">webpage</a>]
                            </span>
                        </li>
                    </ul>
                    <div class="vspace_small"></div>
                </li>
                <li>
                    <p class="publications">SceneTextGen: Layout-Agnostic Scene Text Image Synthesis with Diffusion Models</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                Qilong Zhangli, <span style="text-decoration: underline;">Jindong Jiang</span>, Di Liu, Licheng Yu, Xiaoliang Dai, Ankit Ramchandani, Guan Pang, Dimitris N. Metaxas, Praveen Krishnan
                            </span>
                        </li>
                        <li>
                            <span class="dest"> CVPR 2024 </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/2406.01062">paper</a>]
                            </span>
                        </li>
                    </ul>
                    <div class="vspace_small"></div>
                </li>
                <li>
                    <p class="publications">Object-Centric Slot Diffusion</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                <span style="text-decoration: underline;">Jindong Jiang</span>, Fei Deng, Gautam Singh,
                                Sungjin Ahn
                            </span>
                        </li>
                        <li>
                            <span class="dest"> NeurIPS 2023 </span>
                            <span class="special"> ðŸŒŸSpotlightðŸŒŸ (top 3% = 378/12343) </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/2303.10834">paper</a>]
                                [<a href="https://latentslotdiffusion.github.io/">webpage</a>]
                            </span>
                        </li>
                    </ul>
                    <!-- <p>&nbsp;</p> -->
                    <div class="vspace_small"></div>
                </li>
                <li>
                    <p class="publications">Generative Neurosymbolic Machines</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                <span style="text-decoration: underline;">Jindong Jiang</span> and Sungjin Ahn
                            </span>
                        </li>
                        <li>
                            <span class="dest"> NeurIPS 2020 </span>
                            <span class="special"> ðŸŒŸSpotlightðŸŒŸ (top 4% = 395/9454) </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/2010.12152">paper</a>]
                                [<a href="https://github.com/JindongJiang/GNM">code</a>]
                            </span>
                        </li>
                    </ul>
                    <!-- <p>&nbsp;</p> -->
                    <div class="vspace_small"></div>
                </li>
                <li>
                    <p class="publications">Improving Generative Imagination in Object-Centric World Models</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                Zhixuan Lin, Yi-Fu Wu, Skand Peri, Bofeng Fu, <span
                                    style="text-decoration: underline;">Jindong Jiang</span>, Sungjin Ahn
                            </span>
                        </li>
                        <li>
                            <span class="dest">
                                ICML 2020
                            </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/2010.02054">paper</a>]
                                [<a href="https://sites.google.com/view/gswm/home">webpage</a>]
                            </span>
                        </li>
                    </ul>
                    <!-- <p>&nbsp;</p> -->
                    <div class="vspace_small"></div>

                </li>
                <li>
                    <p class="publications">SCALOR: Generative World Models with Scalable Object Representations</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                { <span style="text-decoration: underline;">Jindong Jiang</span>, Sepehr Janghorbani },
                                Gerard de Melo, Sungjin Ahn
                            </span>
                        </li>
                        <li>
                            <span class="dest">
                                ICLR 2020
                            </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/1910.02384">paper</a>]
                                [<a href="https://sites.google.com/view/scalor">webpage</a>]
                            </span>
                        </li>
                    </ul>
                    <!-- <p>&nbsp;</p> -->
                    <div class="vspace_small"></div>
                </li>
                <li>
                    <p class="publications">SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention
                        and Decomposition</p>
                    <ul>
                        <li>
                            <span class="collaborators">
                                { Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri }, Weihao Sun, Gautam Singh, Fei Deng,
                                <span style="text-decoration: underline;">Jindong Jiang</span>, Sungjin Ahn
                            </span>
                        </li>
                        <li>
                            <span class="dest">
                                ICLR 2020
                            </span>
                            <span class="pdf_project">
                                [<a href="https://arxiv.org/abs/2001.02407">paper</a>]
                                [<a href="https://sites.google.com/view/space-project-page">webpage</a>]
                            </span>
                        </li>
                    </ul>
                    <!-- <p>&nbsp;</p> -->
                    <div class="vspace_small"></div>
                </li>
            </ul>
            <hr />
            <h3>My Name</h3>
            <p>
                My Chinese name is "<span style="color: rgb(187, 116, 56);">æ±Ÿé”¦ä¸œ</span>", it can be pronounced as "Jiang
                Jindong" in Mandarin, and "Gong Kam Dong" in Guangdong dialect (also known as Cantonese). As ChatGPT once cleverly put it,
                "<span style="color: rgb(187, 116, 56);">æ±Ÿ</span>" stands for river, giving a nice flow to the name, while "<span
                    style="color: rgb(187, 116, 56);">é”¦</span>" jazzes things up, representing brocade or ornamental cloth.
                Then we've got "<span style="color: rgb(187, 116, 56);">ä¸œ</span>" which means east, adding a sense of direction. 
                So, when you put them all together, you end up with a quirky name that doesn't quite translate directly into English.
            </p>
        </div>


</body>

</html>
